{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7-3_dl_cv_mask_rcnn_video_inference_220726.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1IFBnysYRLPqkQ4CjfUvmELXZ-QmAvBY1","authorship_tag":"ABX9TyPi2JF7ZYxTtTRUfs8b6wKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### **Mask R-CNN video inference**"],"metadata":{"id":"ZG_9Xo1b0jwa"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time"],"metadata":{"id":"iaz1IiZEr-F4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir ./pretrained\n","!wget -O ./pretrained/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","!wget -O ./pretrained/config_mask_graph.pbtxt https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9jZapK2onlx","executionInfo":{"status":"ok","timestamp":1660315740835,"user_tz":-540,"elapsed":1359,"user":{"displayName":"Jisu Lee","userId":"06300400708851269649"}},"outputId":"b618831a-840a-4ab6-84cd-b1576e309372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-12 14:48:59--  http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.45.112, 2607:f8b0:4004:83f::2010\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.45.112|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 177817887 (170M) [application/x-tar]\n","Saving to: ‘./pretrained/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz’\n","\n","./pretrained/mask_r 100%[===================>] 169.58M   315MB/s    in 0.5s    \n","\n","2022-08-12 14:48:59 (315 MB/s) - ‘./pretrained/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz’ saved [177817887/177817887]\n","\n","--2022-08-12 14:48:59--  https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 182896 (179K) [text/plain]\n","Saving to: ‘./pretrained/config_mask_graph.pbtxt’\n","\n","./pretrained/config 100%[===================>] 178.61K  --.-KB/s    in 0.005s  \n","\n","2022-08-12 14:49:00 (36.2 MB/s) - ‘./pretrained/config_mask_graph.pbtxt’ saved [182896/182896]\n","\n"]}]},{"cell_type":"code","source":["!tar -xvf ./pretrained/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz -C ./pretrained"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsvmCAnTonoJ","executionInfo":{"status":"ok","timestamp":1660315742715,"user_tz":-540,"elapsed":1883,"user":{"displayName":"Jisu Lee","userId":"06300400708851269649"}},"outputId":"ccead68f-32f2-4d66-e651-71d27e30df84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mask_rcnn_inception_v2_coco_2018_01_28/\n","mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.index\n","mask_rcnn_inception_v2_coco_2018_01_28/checkpoint\n","mask_rcnn_inception_v2_coco_2018_01_28/pipeline.config\n","mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n","mask_rcnn_inception_v2_coco_2018_01_28/model.ckpt.meta\n","mask_rcnn_inception_v2_coco_2018_01_28/saved_model/\n","mask_rcnn_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n","mask_rcnn_inception_v2_coco_2018_01_28/saved_model/variables/\n","mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"]}]},{"cell_type":"code","source":["labels_to_names_seq = {0:'person',1:'bicycle',2:'car',3:'motorcycle',4:'airplane',5:'bus',6:'train',7:'truck',8:'boat',9:'traffic light',\n","                       10:'fire hydrant',11:'street sign',12:'stop sign',13:'parking meter',14:'bench',15:'bird',16:'cat',17:'dog',18:'horse',19:'sheep',\n","                       20:'cow',21:'elephant',22:'bear',23:'zebra',24:'giraffe',25:'hat',26:'backpack',27:'umbrella',28:'shoe',29:'eye glasses',\n","                       30:'handbag',31:'tie',32:'suitcase',33:'frisbee',34:'skis',35:'snowboard',36:'sports ball',37:'kite',38:'baseball bat',39:'baseball glove',\n","                       40:'skateboard',41:'surfboard',42:'tennis racket',43:'bottle',44:'plate',45:'wine glass',46:'cup',47:'fork',48:'knife',49:'spoon',\n","                       50:'bowl',51:'banana',52:'apple',53:'sandwich',54:'orange',55:'broccoli',56:'carrot',57:'hot dog',58:'pizza',59:'donut',\n","                       60:'cake',61:'chair',62:'couch',63:'potted plant',64:'bed',65:'mirror',66:'dining table',67:'window',68:'desk',69:'toilet',\n","                       70:'door',71:'tv',72:'laptop',73:'mouse',74:'remote',75:'keyboard',76:'cell phone',77:'microwave',78:'oven',79:'toaster',\n","                       80:'sink',81:'refrigerator',82:'blender',83:'book',84:'clock',85:'vase',86:'scissors',87:'teddy bear',88:'hair drier',89:'toothbrush',\n","                       90:'hair brush'}"],"metadata":{"id":"7GECw8s6osIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["colors = list(\n","    [[0, 255, 0],\n","     [0, 0, 255],\n","     [255, 0, 0],\n","     [0, 255, 255],\n","     [255, 255, 0],\n","     [255, 0, 255],\n","     [80, 70, 180],\n","     [250, 80, 190],\n","     [245, 145, 50],\n","     [70, 150, 250],\n","     [50, 190, 190]])"],"metadata":{"id":"OjmIgIS7osLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_box_info(box, image_width, image_height):\n","  class_id = int(box[1])\n","  x1 = int(image_width * box[3])\n","  y1 = int(image_height * box[4])\n","  x2 = int(image_width * box[5])\n","  y2 = int(image_height * box[6])\n","\n","  x1 = max(0, min(x1, image_width-1))\n","  y1 = max(0, min(y1, image_height-1))\n","  x2 = max(0, min(x2, image_width-1))\n","  y2 = max(0, min(y2, image_height-1))\n","  return class_id, x1, y1, x2, y2\n","\n","def draw_box(draw_image, box, image_width, image_height):\n","  green_color=(0, 255, 0)\n","  red_color=(0, 0, 255)\n","  confidence_score = box[2]    \n","  class_id, x1, y1, x2, y2 = get_box_info(box, image_width, image_height)\n","  text = '{}: {:.4f}'.format(labels_to_names_seq[class_id], confidence_score)\n","  cv2.rectangle(draw_image, (x1, y1), (x2, y2), green_color, thickness=2)\n","  cv2.putText(draw_image, text, (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, red_color, 1)\n","  return draw_image\n","\n","def draw_mask(draw_image, box, mask, image_width, image_height, mask_threshold):\n","  class_id, x1, y1, x2, y2 = get_box_info(box, image_width, image_height)\n","  class_mask_detected = mask[class_id]\n","  class_mask_scaled = cv2.resize(class_mask_detected, (x2-x1+1, y2-y1+1))\n","  class_mask_scaled_bool = (class_mask_scaled > mask_threshold)\n","  \n","  colorIndex = np.random.randint(0, len(colors)-1)\n","  color = colors[colorIndex]\n","  before_masking_roi = draw_image[y1:y2+1, x1:x2+1]\n","  after_masking_roi = before_masking_roi\n","  after_masking_roi_bool = after_masking_roi[class_mask_scaled_bool]\n","  after_masking_roi[class_mask_scaled_bool] = ([0.3 * color[0], 0.3 * color[1], 0.3 * color[2]] + 0.6 * after_masking_roi_bool).astype('uint8')\n","\n","  class_mask_scaled_int = class_mask_scaled_bool.astype('uint8')\n","  contours, hierarchy = cv2.findContours(class_mask_scaled_int, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","  cv2.drawContours(after_masking_roi, contours, -1, color, 1)\n","  return draw_image"],"metadata":{"id":"cZAZYDlW_Ynt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_image_mask_rcnn(cv_net, image, confidence_threshold, mask_threshold, use_copied_image=True):\n","  if use_copied_image:\n","    draw_image = image.copy()\n","  else:\n","    draw_image = image\n","\n","  image_height = draw_image.shape[0]\n","  image_width = draw_image.shape[1]\n","        \n","  start_time = time.time() \n","  cv_net.setInput(cv2.dnn.blobFromImage(draw_image, swapRB=True, crop=False))\n","  boxes_out, masks_out = cv_net.forward(['detection_out_final', 'detection_masks'])\n","  inference_time = time.time() - start_time\n","  print(f'inference time : {np.round(inference_time)}초')\n","\n","  boxes_detections_nums = boxes_out.shape[2]\n","  masks_classes_nums = masks_out.shape[1]\n","\n","  for i in range(boxes_detections_nums):\n","    box = boxes_out[0, 0, i, :]\n","    mask = masks_out[i, :, :, :]\n","    confidence_score = box[2]\n","    if confidence_score > confidence_threshold:\n","      draw_box(draw_image, box, image_width, image_height)\n","      draw_mask(draw_image, box, mask, image_width, image_height, mask_threshold)\n","  return draw_image"],"metadata":{"id":"as9NvuZ3_Yyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def detect_video_mask_rcnn(cv_net, input_path, output_path, confidence_threshold, mask_threshold):\n","  cap = cv2.VideoCapture(video_input_path)\n","  codec = cv2.VideoWriter_fourcc(*'XVID')\n","  video_fps = round(cap.get(cv2.CAP_PROP_FPS))\n","  video_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","  frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  video_writer = cv2.VideoWriter(video_output_path, codec, video_fps, video_size)\n","  print(f'frame count : {frame_count}, video fps : {video_fps}, video size : {video_size}')\n","\n","  frame_index=0\n","  while True:\n","    hasframe, image_frame = cap.read()\n","    frame_index += 1\n","    if not hasframe:\n","      print('process completed')\n","      break\n","    print(f'frame index : {frame_index}')\n","    frame = detect_image_mask_rcnn(cv_net, image_frame, confidence_threshold=confidence_threshold , mask_threshold=mask_threshold, use_copied_image=False)\n","    video_writer.write(frame)\n","  \n","  video_writer.release()\n","  cap.release()"],"metadata":{"id":"J5RviISijIOy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["video_input_path = './John_Wick_small.mp4'\n","video_output_path = './drive/MyDrive/Colab Notebooks/update/dl_cv/7_dl_cv_mask_rcnn_inference/data/John_Wick_small_output.avi'\n","\n","cv_net = cv2.dnn.readNetFromTensorflow('./pretrained/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb', './pretrained/config_mask_graph.pbtxt')\n","detect_video_mask_rcnn(cv_net, video_input_path, video_output_path, confidence_threshold=0.5, mask_threshold=0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUaCZhQVjIMK","executionInfo":{"status":"ok","timestamp":1660316111025,"user_tz":-540,"elapsed":235702,"user":{"displayName":"Jisu Lee","userId":"06300400708851269649"}},"outputId":"c6f3c0ca-fbbc-4a8d-8530-ddb9f58266e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["frame count : 58, video fps : 30, video size : (1072, 460)\n","frame index : 1\n","inference time : 4.0초\n","frame index : 2\n","inference time : 4.0초\n","frame index : 3\n","inference time : 4.0초\n","frame index : 4\n","inference time : 4.0초\n","frame index : 5\n","inference time : 4.0초\n","frame index : 6\n","inference time : 4.0초\n","frame index : 7\n","inference time : 5.0초\n","frame index : 8\n","inference time : 4.0초\n","frame index : 9\n","inference time : 4.0초\n","frame index : 10\n","inference time : 4.0초\n","frame index : 11\n","inference time : 4.0초\n","frame index : 12\n","inference time : 4.0초\n","frame index : 13\n","inference time : 4.0초\n","frame index : 14\n","inference time : 4.0초\n","frame index : 15\n","inference time : 4.0초\n","frame index : 16\n","inference time : 4.0초\n","frame index : 17\n","inference time : 4.0초\n","frame index : 18\n","inference time : 4.0초\n","frame index : 19\n","inference time : 4.0초\n","frame index : 20\n","inference time : 4.0초\n","frame index : 21\n","inference time : 4.0초\n","frame index : 22\n","inference time : 4.0초\n","frame index : 23\n","inference time : 4.0초\n","frame index : 24\n","inference time : 4.0초\n","frame index : 25\n","inference time : 4.0초\n","frame index : 26\n","inference time : 4.0초\n","frame index : 27\n","inference time : 4.0초\n","frame index : 28\n","inference time : 4.0초\n","frame index : 29\n","inference time : 4.0초\n","frame index : 30\n","inference time : 4.0초\n","frame index : 31\n","inference time : 4.0초\n","frame index : 32\n","inference time : 4.0초\n","frame index : 33\n","inference time : 4.0초\n","frame index : 34\n","inference time : 4.0초\n","frame index : 35\n","inference time : 4.0초\n","frame index : 36\n","inference time : 4.0초\n","frame index : 37\n","inference time : 4.0초\n","frame index : 38\n","inference time : 4.0초\n","frame index : 39\n","inference time : 4.0초\n","frame index : 40\n","inference time : 4.0초\n","frame index : 41\n","inference time : 5.0초\n","frame index : 42\n","inference time : 4.0초\n","frame index : 43\n","inference time : 4.0초\n","frame index : 44\n","inference time : 4.0초\n","frame index : 45\n","inference time : 4.0초\n","frame index : 46\n","inference time : 4.0초\n","frame index : 47\n","inference time : 4.0초\n","frame index : 48\n","inference time : 4.0초\n","frame index : 49\n","inference time : 4.0초\n","frame index : 50\n","inference time : 4.0초\n","frame index : 51\n","inference time : 4.0초\n","frame index : 52\n","inference time : 4.0초\n","frame index : 53\n","inference time : 4.0초\n","frame index : 54\n","inference time : 4.0초\n","frame index : 55\n","inference time : 4.0초\n","frame index : 56\n","inference time : 4.0초\n","frame index : 57\n","inference time : 4.0초\n","frame index : 58\n","inference time : 4.0초\n","process completed\n"]}]}]}